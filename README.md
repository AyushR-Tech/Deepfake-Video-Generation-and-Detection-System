# DeepFake AI System

A Streamlit app that provides:
- Deepfake detection (VAE + ViT + heuristic fallback)
- Image generation (GAN via a checkpoint wrapper + Stable Diffusion img2img via a local diffusers pipeline)
- Sidebar helpers to upload and load checkpoints and the local Stable Diffusion pipeline
- Lightweight ethics/usage scaffolding and basic UI

This README was updated to reflect recent changes: the app now includes a GAN upload control, checkpoint loader that no longer attempts to load a legacy diffusion state file, a cached local-only Stable Diffusion loader, and integrated detection UI.

---

## File layout (important)
- app.py â€” main Streamlit application (UI + logic)
- stable_diffusion/sd_utils.py â€” helper to load a local diffusers pipeline and run img2img
- scripts/download_diffusers_model.py â€” (optional) helper to download & save a diffusers pipeline locally
- progan_generator_final.pt â€” GAN checkpoint (place in project root or upload via the app sidebar)
- vae_model.pth, best_vit_deepfake_detector.pt â€” detector checkpoints (optional)
- stable_diffusion/local_model/ â€” local diffusers pipeline directory (required for SD img2img)
- requirements.txt â€” Python dependencies
- .gitignore, .gitattributes â€” repository config (do NOT commit large model binaries)

---

## Key changes / notes
- The checkpoint loader now looks for VAE, ViT and GAN checkpoints only (no state-dict diffusion file).
- The app provides a GAN checkpoint uploader in the sidebar; uploaded checkpoint is saved into the project folder so you can press "Load Checkpoint Models".
- Stable Diffusion is loaded only from a local folder (`stable_diffusion/local_model`) and is cached using Streamlit's cache_resource; the app will not attempt to download models automatically.
- SciPy is required by default (used for remapping and convolution). The app offers a lower-quality fallback if SciPy is unavailable, but install SciPy for best results.

---

## Prerequisites
- Python 3.8â€“3.11
- (Recommended) Virtual environment: venv or conda
- For GPU: install a matching PyTorch wheel for your CUDA version (see https://pytorch.org/get-started/locally)

---

## Install & setup (Windows PowerShell)
1. Create & activate venv
   ```powershell
   python -m venv .venv
   .\.venv\Scripts\Activate.ps1
   python -m pip install --upgrade pip
   ```

2. Install PyTorch (pick correct command from PyTorch website). Examples:
   - CPU-only:
     ```powershell
     pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
     ```
   - CUDA (replace cu118 or version as appropriate):
     ```powershell
     pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
     ```

3. Install the rest of dependencies:
   ```powershell
   pip install -r requirements.txt
   ```

4. (Optional) Reduce TensorFlow oneDNN info messages:
   ```powershell
   $env:TF_ENABLE_ONEDNN_OPTS = "0"
   ```

---

## Where to place model files (important)
- GAN checkpoint (`progan_generator_final.pt`)
  - Place in project root (same folder as `app.py`) OR in `models/`.  
  - Alternatively upload via the app sidebar â€” the app will save it as `progan_generator_final.pt` to the project folder.
- Detector checkpoints (`vae_model.pth`, `best_vit_deepfake_detector.pt`)
  - Place in project root or `models/`.
- Stable Diffusion (img2img)
  - Must be a diffusers pipeline saved locally at `stable_diffusion/local_model/`. The folder must include pipeline files (config.json, unet, vae, text_encoder/tokenizer, etc.).
  - You can create this local folder by running the included helper script or by saving a pipeline in another environment and zipping / copying it into this folder.

Helper to download & save a local SD pipeline (example):
- Edit `scripts/download_diffusers_model.py` with your HF token and desired model id, then run:
  ```powershell
  $env:HF_TOKEN="your_hf_token"
  python .\scripts\download_diffusers_model.py
  ```

---

## Run the app
From project root:
```powershell
.\.venv\Scripts\Activate.ps1
streamlit run app.py
```
Open the URL printed by Streamlit (usually http://localhost:8501).

---

## Typical usage flow (in the app)
1. Sidebar:
   - Upload your `progan_generator_final.pt` with "Upload GAN checkpoint" (optional).
   - Click "ðŸ”„ Load Checkpoint Models" to load VAE / ViT / GAN wrappers (this enables detection and GAN generation).
   - Click "ðŸ”„ Load Stable Diffusion Pipeline" to load the local SD pipeline (one-time per session); the pipeline is cached.
2. Detection tab:
   - Upload an image and click "ðŸ” Analyze Image" to get VAE / ViT / ensemble predictions and the heuristic fallback.
3. Generation tab:
   - Upload an image, choose "GAN (state)" to use the GAN checkpoint, or "Diffusion (img2img)" to use the loaded local SD pipeline, then click "ðŸŽ¨ Generate".

---

## Sharing models with collaborators
- Do NOT commit large model binaries into git (GitHub blocks >100MB). Use one of:
  - Git LFS (track `.pt`, `.pth`, `.ckpt`, `.bin`) â€” recommended for moderately large files.
  - Upload zipped `stable_diffusion/local_model` and GAN checkpoint to Google Drive / Dropbox / GitHub Releases; collaborators download and extract into project folders.
- Example: zip `stable_diffusion/local_model` and instruct collaborators to extract into `stable_diffusion/local_model/`.

---

## Troubleshooting / common issues
- ModuleNotFoundError: SciPy â€” install via `pip install scipy`.
- "Load checkpoint models first" â€” ensure you pressed the "Load Checkpoint Models" button in the sidebar after placing/uploading `progan_generator_final.pt`.
- Stable Diffusion load shows "Loading pipeline components..." â€” this is normal during initialization; if you did not use a local model folder the loader may try to download or fail. Ensure `stable_diffusion/local_model` exists and contains the saved pipeline.
- PyTorch + CUDA mismatch â€” install the correct torch wheel for your CUDA runtime.
- If you intend to track model files in git, enable Git LFS:
  ```powershell
  git lfs install
  git lfs track "*.pt" "*.pth" "*.ckpt" "*.bin"
  git add .gitattributes
  git commit -m "Track model files with Git LFS"
  ```

---

## Security & ethics
- The app includes an Ethical Safeguards scaffold but is intended for research / educational use only.
- Respect privacy, copyright and legal restrictions when using datasets or deploying generated images.

---

## Additional notes
- The app provides heuristic fallbacks when checkpoints are missing; results may be lower quality.
- Stable Diffusion on CPU is slow â€” use GPU where available.
- If you want a direct zipped package of `stable_diffusion/local_model` for distribution, upload it to a cloud host and provide the download link